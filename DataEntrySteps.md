1) Запрос заказчика / инициатора
 • Требуется лёгкая mini-SIEM-система, предназначенная для быстрого запуска локально/в Docker и демонстрации базовой ценности мониторинга ИБ.
 • Система должна работать «из коробки»: принять логи (или демо-генератор), превратить их в события, выполнить детектирование и показать результат в интерфейсе.
 • Принципиальное ограничение на старте — отказ от тяжёлой инфраструктуры (в отличие от ELK/Splunk), т.е. без обязательного развёртывания серверных компонентов и сложного администрирования.
 • Требование к устойчивости: сбор событий должен быть tail-подобным (почти в реальном времени) и поддерживать возобновление работы после перезапуска без потери позиции чтения.

 Почему не берем «как у больших»
 • Splunk — классный enterprise-уровень, но у него модель, завязанная на объём ingest/нагрузки, и это обычно воспринимается как “дорого/избыточно” для маленьких сценариев (у Splunk даже калькуляторзавязан на GB ingested/day).  
Наша задача: сделать “воткнул и работает” без enterprise-цены и без тяжёлого внедрения.

⸻

2) Стратегические цели организации
 • Time-to-Value: минимальное время от запуска до первого результата — графики/топы/алерты должны появляться за минуты (включая режим демонстрации на тестовых данных).
 • Унификация данных: разнородные логи должны приводиться к единому формату Event (единая схема), чтобы детекты и аналитика не зависели от специфики конкретного источника.
 • Понятная демонстрация цепочки: «сырые строки логов → нормализованные события → срабатывание правила → алерт → связанные события и доказательная база».
 • Гибкость через конфигурацию: управление источниками, правилами и порогами через централизованный config.yaml (валидация, дефолты) с возможностью быстро менять поведение детектов без переработки кода.
 • Готовая базовая аналитика: методы агрегации для дашборда (например, подсчёт 4xx, топ IP, поиск/фильтры) без сложных зависимостей и “ручной аналитики”.

⸻

3) Нормативные и правовые ограничения
 • Система обрабатывает потенциально чувствительную информацию: IP-адреса, учётные записи, сырые строки логов, где могут встречаться токены/секреты. Поэтому на этапе ингеста должна быть заложена минимизация данных (сбор только того, что нужно для детектов и расследования; возможность фильтрации очевидно лишнего).
 • Для расследования и прозрачности детектов требуется сохранение исходной строки (raw) в неизменном виде (без усечений), чтобы алерт можно было подтвердить “первоисточником”.
 • Необходимо учитывать практику retention/жизненного цикла данных: локальная БД не должна бесконечно расти, должна существовать политика хранения и очистки (например, по параметрам из config.yaml).
 • Контроль доступа: сбор и чтение логов должны выполняться под учётной записью с минимально необходимыми правами, без избыточных привилегий.

⸻

4) Внешняя среда
 • Продукт позиционируется как внутренний/учебный инструмент без сложной ролевой модели и тяжёлых корпоративных интеграций на старте.
 • Архитектурный контекст — монолитный MVP: единое приложение + локальное хранилище, без распределённой инфраструктуры и очередей сообщений (Kafka и т.п.) в рамках текущей версии.
 • Технологический контекст интерфейса — веб-дашборд на базе FastAPI + шаблоны + графики: акцент на наглядности и простоте демонстрации (Overview/Alerts/Search).
 • В части достоверности данных важно корректное время событий: фиксирование точных timestamp’ов и опора на корректно настроенное системное время (NTP как ожидаемая практика в логировании/аудите).

⸻

5) Допущения и ограничения
 • Допущение по окружению: для MVP достаточно ресурсов одного узла (локально/Docker) и локального доступа к файлам логов.
 • Ограничение по функциональности: в MVP не реализуются распределённые агенты, сложная корреляция “как в enterprise-SIEM”, ML/аномалистика; детектирование — правила и пороги.
 • Ограничение по источникам/форматам: принимается, что логи соответствуют стандартным форматам (например, nginx combined, syslog-подобные auth.log); кастомные форматы требуют отдельной доработки парсеров/нормализаторов.
 • Требования к производительности ингеста (ориентиры): сборщик должен быть ресурсно эффективным (порядка единиц процентов CPU и сотен МБ RAM на инстанс) и поддерживать демо-поток (например, ≥100 событий/сек) для проверки пайплайна.
• Требования к хранилищу/конкурентности: запись событий и чтение для дашборда должны работать параллельно; нужны индексы по ключевым полям (время, IP, источник, тип события) и пакетная запись, чтобы избежать избыточных транзакционных накладных расходов. Для восстановления после рестарта должна быть предусмотрена фиксация позиций чтения (служебное состояние).
